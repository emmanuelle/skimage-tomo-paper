%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
%\documentclass{bmcart}

%%% Load packages
\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
\RequirePackage[breaklinks=true]{hyperref}
\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\def\includegraphic{}
%\def\includegraphics{}

\definecolor{listinggray}{gray}{0.1}
\definecolor{lbcolor}{rgb}{0.9,0.92,0.95}
\lstset{
	backgroundcolor=\color{lbcolor},
	tabsize=4,
	rulecolor=,
	language=Python,
        basicstyle=\scriptsize,
        %upquote=true,
        aboveskip={1.5\baselineskip},
        columns=fixed,
        showstringspaces=false,
        extendedchars=true,
        breaklines=true,
        prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
        frame=single,
        %showtabs=false,
        %showspaces=false,
        %showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
}

%%% Put your definitions there:
\startlocaldefs
\newcommand{\emma}[1]{{\color{blue}{#1}}}

\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Analyzing X-ray images in Python with scikit-image}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff1},                       % id of corresponding address, if any
   %noteref={n1},                        % id's of article notes, if any
   email={emmanuelle.gouillart@saint-gobain.com}   % email address
]{\fnm{Emmanuelle} \snm{Gouillart}}
\author[
   addressref={aff2},
   %email={}
]{\fnm{Juan} \snm{Nunez-Iglesias}}
\author[
   addressref={aff3},
   email={stefanv@berkeley.edu}
]{\fnm{St√©fan} \snm{van der Walt}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{Surface du Verre et Interfaces, UMR 125 CNRS/Saint-Gobain}, % university, etc                     %
  \postcode{93303}                                % post or zip code
  \city{Aubervilliers},                              % city
  \cny{France}                                    % country
}
\address[id=aff2]{%
  \orgname{Victorian Life Sciences Computation Initiative, University of Melbourne},
  %\street{700 Swanston St},
  %\postcode{3053}
  \city{Carlton, VIC},
  \cny{Australia}
}
\address[id=aff3]{%
  \orgname{Division of Applied Mathematics, Stellenbosch University},
  %\street{D\"{u}sternbrooker Weg 20},
  %\postcode{24105}
  \city{Stellenbosch},
  \cny{South Africa}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
%\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
    The exploration and processing of images is a vital aspect of the
    scientific workflow of different X-ray imaging modalities. Users
    require tools combining interactivity, versatility, and performance. 

    \texttt{scikit-image} is an open-source image processing toolkit for
    the Python language, that supports a large variety of file formats
    and is compatible with 2-D and 3-D images. The toolkit exposes a
    simple programming interface, with thematic modules grouping
    functions according to their purpose, such as image restoration,
    segmentation, and measurements. \texttt{scikit-image} users benefit
    from the rich ecosystem of Python for science, with powerful
    visualization libraries or machine learning toolkits.
    \texttt{scikit-image} combines a gentle
    learning curve, versatile image processing capabilities, and the
    scalable performances required for the high-throughput analysis of
    X-ray imaging data.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{scikit-image}
\kwd{Python}
\kwd{image processing library}
\kwd{3-D image}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%
\section*{Introduction}

The acquisition time of synchrotron tomography images has decreased
dramatically over the last decade, from hours to
seconds \citep{Maire2014}. New modalities such as single-bunch
imaging \citep{Rack2014} provide a time resolution down to the nanosecond
for radiography. However, the time subsequently spent in processing the
images has not decreased as much, so that the outcome of a successful
synchrotron imaging campaign often takes weeks or even months to be
transformed into scientific results. 

Transforming billions of pixels and voxels to a few meaningful figures
represents a tremendous data reduction. Often, the sequence of operations
needed to produce these data is not known beforehand, or might be altered
due to artifacts \citep{Marone2010}, or to an unforeseen evolution of
the sample. Image processing necessarily involves trial and error phases
to choose the processing workflow. Therefore, image processing tools need
to offer at the same time enough flexibility of use, a variety of
algorithms, and efficient implementations to allow for fast iterations
while adjusting the workflow.

Several software applications and libraries are available to synchrotron
users to process their images. ImageJ \citep{Abramoff2004, Schneider2012}
and its distribution Fiji \citep{Schindelin2012} is a popular tool for
2-D and 3-D images, thanks to its intuitive menus and graphical tools,
and the wealth of plugins contributed by a vivid
community \citep{Schindelin2015}. For 3-D images, commercial tools such
as Avizo 3D software (TM) are appreciated for an intuitive graphical
pipeline and advanced 3D visualization. Alternatively, the use of a
programming language gives finer control and more possibilities, provided
classical processing algorithms can be called from libraries -- hence
limiting the programming task and the risk of bugs. Matlab (TM) and its
image processing toolbox are popular in the academic community of
computer vision and image processing. The Python language is widely used
in the scientific world and in synchrotron facilities. As a
general-purpose language, Python is used in synchrotrons to control
device servers \citep{pytango}, to access raw data of X-ray
detectors \citep{Knudsen2013}, to reconstruct tomography volumes from
radiographs \citep{Gursoy2014, Mirone2014}, and in data
processing packages for macromolecular cristallography \citep{Adams2010},
azimuthal integration of diffraction data \citep{Ashiotis2015}, or
fluorescence analysis \citep{pymca}.

\texttt{scikit-image} \citep{Vanderwalt2014} is a general-purpose image
processing library for the Python language, and a component of the ecosystem of
Python scientific modules commonly known as Scientific
Python \citep{Oliphant2007}. Like the rest of the ecosystem,
\texttt{scikit-image} is released under a permissive open-source license and is
available free of charge. Most of \texttt{scikit-image} is compatible with both 2-D and
3-D images, so that it can be used for a large number of imaging modalities,
such as microscopy, radiography or tomography. In this article, we explain how
\texttt{scikit-image} can be used for processing data acquired in X-ray
imaging experiments, with a focus on microtomography 3-D images. This
article does not intend to be a pedagogical tutorial on \texttt{scikit-image}
for X-ray imaging, but rather to explain the rationale behind the package, and
provide various examples of its capabilities.

\section*{Overview and first steps}

In this section, we provide a short overview of the typical use patterns of
\texttt{scikit-image}, illutrated by short snippets of code. Indeed, since
Python is a programming language, the user interacts with data objects and
images through code, which is either typed and executed in an interactive
interpreter, or written in text files (scripts) that are executed. 

\begin{figure*}
    \centerline{\includegraphics[width=0.8\textwidth]{ecosystem_landscape}}
    \caption{\csentence{\texttt{scikit-image} and the Scientific Python
	ecosystem}. Images are opened from files as \texttt{NumPy}
	arrays. Functions of \texttt{scikit-image} transform image arrays
	into other arrays with the same dimensions, or into arrays of
	numbers corresponding to features of the image. The output of
	scikit-image functions can be passed to other Python modules
	relying on \texttt{NumPy} arrays, such as \texttt{SciPy} or
	\texttt{scikit-learn}. Image-shaped arrays are transformed into
	visualizations with \texttt{matplotlib} (2D) or \texttt{Mayavi}
	(3D). A variety of environments is available for code development
	and execution, from classical IDEs to Jupyter notebooks.
    \label{fig:ecosystem}}
\end{figure*}


Images are manipulated as numerical arrays of uniform
data type, a format that guarantees a fast access to the computer memory. The
n-dimensional (2-D, 3-D, \dots) numerical array object is provided by the
\texttt{NumPy} module \citep{Vanderwalt2011}.

In image processing, one of the first tasks is therefore to generate
\texttt{NumPy} arrays, which is often done by reading data from files. We
read one 2-D image from a file and display it with the following lines of code:

\lstinputlisting[language=Python]{io.py} 

\texttt{skimage} is the name under which \texttt{scikit-image} is imported in
Python code. Note that functions (such as \texttt{imread} to read an image
file, or \texttt{imshow} to display an image) are found in thematic submodules of
\texttt{skimage}, such as \texttt{io} for Input/Output.

A stack of 2-D images, such as tomography slices generated by a reconstruction algorithm, can be opened as an image collection or a 3-D array:
\lstinputlisting[language=Python]{io_coll.py}
Raw data formats can be opened using the \texttt{NumPy} functions \texttt{fromfile} or \texttt{memmap}, and \texttt{hdf5} files are opened using modules such as \texttt{h5py} or \texttt{pytables}.

\texttt{scikit-image} has a simple Application Programming Interface
(API), based almost only on
functions. Most functions take an image (\emph{i.e} a multi-dimensional
array) as input parameter:
\begin{lstlisting}
>>> from skimage import filters
>>> im_gaussian = filters.gaussian(im)
\end{lstlisting}

Optional parameters can be passed as Python's \emph{keyword arguments},
in addition to the image parameter.
\begin{lstlisting}
>>> im_gaussian = filters.gaussian(im, sigma=3, mode='wrap')
\end{lstlisting}
A few functions require several arrays to be passed, such as the
watershed segmentation algorithm that takes as parameters the image to be
segmented, and an image of markers from which labels are propagated:
\begin{lstlisting}
>>> from skimage import morphology
>>> labels = morphology.watershed(im, markers)
\end{lstlisting}
Therefore, the image processing workflow can be considered as a directed graph
(a richer structure than a linear pipeline), where nodes are image-shaped arrays, and
edges are functions of \texttt{scikit-image} transforming the arrays (see
Fig.~\ref{fig:ecosystem}).

Most functions transparently handle 2-D, 3-D, or even higher-dimensional
images as arguments, so
the same functions can be used to process tomography, microscopy, or natural
images. A few functions do not support 3-D images and raise an error
when passed a 3-D argument:
\begin{lstlisting}
>>> filters.prewitt(im)
[...]
ValueError: The parameter `image` must be a 2-dimensional array
\end{lstlisting}

However, the proportion of functions supporting 3D images is always increasing,
thanks to the many contributors to the library.

A subset of functions returns not images but other value types,
such as pixel coordinates of objects of interest, or statistical
information about the image:
\begin{lstlisting}
>>> from skimage import exposure
>>> counts, bins = exposure.histogram(im)
>>> counts.shape
(256,)
\end{lstlisting}

\section*{The Python ecosystem}

The benefits of \texttt{scikit-image} for image processing come not only
from the features of the package alone, but also from the rich
environment of Scientific Python \citep{Oliphant2007, Perez2011}.
Fig.~\ref{fig:ecosystem} illustrates how several components of this
ecosystem combine into a sophisticated image processing workflow.

\paragraph{Interpreter and development environment.}

While several interpreters are available to execute Python
instructions and scripts, the most popular one in the scientific world is
the IPython interpreter \citep{Perez2007, Rossant2015}. IPython is an
advanced interpreter, which integrates syntax highlighting, text auto-completion,
a debugger,
introspection and profiling methods, and online help. Several
Integrated Development Environments (IDEs) come bundled with IPython,
together with other components such as a text editor. Notable examples
include Spyder (Fig.~\ref{fig:spyder}), PyCharm, and Visual Studio Code.

\begin{figure*}
    \centerline{\includegraphics[width=0.99\textwidth]{spyder_process}}
    \caption{\csentence{The Spyder IDE} integrates a text editor (with
	syntax highlighting), the IPython interpreter, as well as a panel
	for code introspection (online help, variable explorer, \dots).
 \label{fig:spyder}}
\end{figure*}

The Jupyter notebook \citep{Kluyver2016} is a web application that grew
from the IPython project. Jupyter notebooks provide a development
environment within a web browser, where live code can be enriched
by explanatory text, equations and visualizations (FIGURE).
As of July 2016, more than 500,000 Jupyter notebooks were posted on GitHub,
demonstrating their wide adoption by the community as workflow-sharing
tools (\url{http://archive.ipython.org/media/SciPy2016JupyterLab.pdf}).

\paragraph{NumPy arrays} are the cornerstone of the Scientific Python
ecosystem, and of \texttt{scikit-image} operations in particular.
Cropping or downsampling an image, or retrieving pixels corresponding to
a given label in a segmentation are all one-liners NumPy code. To
illustrate the compactness of NumPy code, modifying pixels values below a
threshold can be written as
\begin{lstlisting}
im[im < 0.5] = 0
\end{lstlisting}
using the ability to index arrays with boolean arrays, called
\emph{masking}. \texttt{NumPy} uses memory sparingly and avoids
making new copies of arrays whenever possible, an important
requirement when dealing with the gigabyte-sized images of tomography.
For example, cropping a subvolume as follows does not create a copy of the
original array:
\begin{lstlisting}
sub_volume = im[100:-100, 100:-100, 100:-100]
\end{lstlisting}


\paragraph{Visualization libraries.}

Visualizing images is an important component of the image processing
workflow, in order to verify the final result and to adjust the
parameters of intermediate processing operations.
\texttt{matplotlib} \citep{Hunter2007} is the most popular 2D plotting
library of the Python ecosystem. It can be used to visualize 2D data such
as color or grayscale images, and 1D data such as contour lines, outlines
of segmented regions, histograms of gray levels, etc. Although
\texttt{matplotlib} has simple 3D plotting capabilities, we
recommend using the \texttt{mayavi} module \citep{Ramachandran2011}
for applications requiring advanced 3D visualization, such as tomography. 
\texttt{mayavi} is based on the VTK toolkit. It exposes a simple API for
visualizing data passed as \texttt{numpy} arrays. For more advanced
visualizations, a large majority of VTK capabilities can be accessed
through its pipeline API.
\texttt{mayavi} offers a good trade-off between simplicity of use for
common operations, and more advanced possibilities, including responsive
visualizations.

\paragraph{Advanced toolkits for signal processing and data science.}

\texttt{scikit-image} is only one Python module that can be used for data
processing, among many others. A very popular module is
\texttt{scikit-learn} \citep{Pedregosa2011}, a Python module for machine
learning using \texttt{NumPy} arrays. If local features of an image
(such as local statistics of gray levels, or geometric points of
interest), or features of segmented objects (e.g. geometrical and
intensity characteristics of segmented particles) are extracted with
functions from \texttt{skimage.feature} (see Fig.~\ref{fig:ecosystem}), it
is then possible to use a \emph{classification} algorithm of
\texttt{scikit-learn}, either for labeling pixels (a segmentation task)
or to classify whole images or objects that have already been segmented.
The near-universal use of \texttt{NumPy} arrays ensures the interoperability
between these packages, so that just a few lines of code are sufficient
to create these sophisticated workflows.

The modularity of the Scientific Python ecosystem may be
confusing at first sight, but the core modules of this ecosystem
are almost perfectly compatible, thanks to the shared use of NumPy arrays
and common development practices (although they are developed in parallel
by different teams). Several ``distributions'', such as Anaconda
or Canopy, bundle together the most popular libraries, including
\texttt{scikit-image}.

\section*{Image processing capabilities}

\begin{figure*}
    \centerline{\includegraphics[width=0.99\textwidth]{tomo_gallery}}
    \caption{\csentence{Typical image processing operations with
	\texttt{scikit-image}.} From left to right and top to bottom.
	Data are synthetic, unless stated otherwise.
	\textbf{Filtering -} Top: non-local means denoising of an image
	with a fine-grained texture, acquired by \emph{in situ}
	synchrotron microtomography during
	glass melting \citep{Gouillart2012}. Bottom: total-variation
	denoising of an image with two phases, corresponding to
	phase-separating silicate melts observed by \emph{in situ
	tomography} \citep{Bouttes2015}.
	\textbf{Feature extraction -} Top: Hubble deep field (NASA,
	public domain), blob detection using the
	Laplacian of Gaussian method. Bottom: ridge detection using the
	leading eigenvalue of the Hessian matrix.
	\textbf{Segmentation - } Top: super-pixel segmentation
	of a CT slice of the human head \citep{tomo_wikipedia}, using
	Felzenszwalb's algorithm \citep{Felzenszwalb2004}. Bottom: random
	walker segmentation (right) of noisy image (top-left corner), using
	histogram-determined markers (bottom-left corner).
	\textbf{Measures -} Top: visualization of local diameter
	(color-coded on the skeleton curve) of an
	interconnected phase (represented in violet).  Bottom: particles color-coded according
	to their extent.
\label{fig:tomo_gallery}}
\end{figure*}

\texttt{scikit-image} offers all the classical operations of image
processing, such as exposure and color adjustment, filtering,
segmentation, features extraction, geometric transformations or
measurements of region characteristics. For these
different categories, the package includes both standard generic
operations and more advanced algorithms. A sample of
\texttt{scikit-image} capabilities is given in
Fig.~\ref{fig:tomo_gallery}.  

Tomographic images often suffer from artifacts or poor signal-to-noise
ratio. Several denoising filters are available for image restoration,
from general-purpose filters such as median and bilateral filters, to
more specific filters. Total-variation denoising \citep{Chambolle2004,
Getreuer2012} is well-suited to restore piecewise-constant images (see
Fig.~\ref{fig:tomo_gallery}), such as images with a small number of
phases encountered in materials science \citep{Bouttes2015}. Conversely,
images with a fine-grained texture are better preserved with non-local
means denoising \citep{Buades2005} (see Fig.~\ref{fig:tomo_gallery}).

\texttt{scikit-image} offers a wide variety of functions to detect
geometrical features of interest in an image. Diffraction peaks in 2D
diffraction images can be extracted using blob detection methods
\citep{Ashiotis2015}, such as the Laplacian of Gaussian method (see
Fig.~\ref{fig:tomo_gallery}). In order to detect thin boundaries, the
ridges of an image can be accessed as regions of high leading eigenvalue
of the local Hessian matrix (see Fig.~\ref{fig:tomo_gallery}).

Segmentation of regions of interest can be achieved using different
strategies, depending on the characteristics of the image. Images with a
clear contrast between regions can be segmented automatically thanks to
several thresholding algorithms, including an adaptive local thresholding
algorithm aimed at images with contrast variations. Super-pixel
algorithms \citep{Felzenszwalb2004, Achanta2012} create an over-segmentation
of images in
super-pixels, by grouping pixels that are close together both in color-
and direct space (see Fig.~\ref{fig:tomo_gallery}). Region-growing
algorithms, such as the morphological
watershed or the random walker \citep{Grady2006}, propagate the labels
of user-defined markers through the image (see
Fig.~\ref{fig:tomo_gallery}). The active contour
algorithm \citep{Kass1988} fits snake contours to features of the
image, such as edges or high-brightness regions.

The characteristics of labeled regions (particles, porosities, organs,
\dots) resulting from a segmentation can be measured using the
\texttt{measure} submodule. The different connected components (e.g.
bubbles or non-touching particles) of a binary image are labeled with the
\texttt{measure.label} function. Properties of labeled regions such as
size, extent, center of mass or mean intensity value are accessed with
\texttt{measure.regionprops} (see Fig.~\ref{fig:tomo_gallery}). Local
characteristics of a region can be retrieved as well:
Fig.~\ref{fig:tomo_gallery} shows how the local diameter of open
porosity is measured by combining a skeletonization of the porosity
channels, and the distance transform to the other phase measured on the
skeleton.   

\paragraph{Performance.}

Given the large size of tomography datasets, the speed of execution of image
processing operations is a critical issue. \texttt{scikit-image} relies mostly
on calls to \texttt{NumPy} operations, with most of them that are performed in
optimized compiled code (C or Fortran). Performance-critical parts of the code
that cannot call efficient \texttt{NumPy} code are implemented in
\texttt{Cython}. \texttt{Cython} \citep{Behnel2011} is an extension of the
Python language that supports explicit type declarations, and is compiled
directly to C. 

However, basic \texttt{scikit-image} code runs on a single core. Computing
workstations and servers used for X-ray imaging typically have several tens of
cores. Parallelization of the computing workflow can be achieved in different
ways. The most trivial parallelization scheme consists in applying the same
workflow to different images, on different cores. However, finer-grained
parallelization is preferable when prototyping the processing workflow.


An easy solution consists in dividing an image into smaller images (with
or without overlap, depending on the operation), and to apply the
same operation on the different sub-images, on different cores. Creating overlapping chunks is easy with the dedicated function \texttt{view\_as\_windows} (or \texttt{view\_as\_blocks} for contiguous non-overlapping chunks):
\begin{lstlisting}[language=Python]
>>> from skimage import util, data
>>> im = data.camera()
>>> im.shape
(512, 512)
>>> # chunks of size 120 with 8-pixel overlap
>>> chunks = util.view_as_windows(im, (128, 128), step=120)
>>> chunks.shape
(4, 4, 128, 128)
\end{lstlisting}
The \texttt{joblib} library enables easy parallel processing. Looping over the different blocks, and dispatching the computation over several cores, is realized with the following syntax:
\begin{lstlisting}
>>> from joblib import Parallel, delayed
>>> filtered_chunks = Parallel(n_jobs=4)(delayed(filters.gaussian)(chunks[i, j]) for i in range(4) for j in range(4))
\end{lstlisting}
\texttt{scikit-image} also offers experimental support for a more integrated parallel processing pipeline, thanks to the \texttt{dask} \citep{dask} module:
\begin{lstlisting}
filtered_im = util.apply_parallel(filters.gaussian, im, depth=8)
\end{lstlisting}
The size of chunks is determined automatically from the number of available cpus, or can be specified by the user.

\em{Caching} provides another tool to speed up data analysis. Prototyping an
image processing workflow often requires several trial and error
executions of scripts containing different operations. \texttt{joblib}
provides a caching mechanism that avoids the repetition of function
calls, if their arguments have not changed:
\begin{lstlisting}
>>> from skimage import filters, data
>>> from joblib import Memory
>>> mem = Memory(cachedir='/tmp/joblib')
>>> median = mem.cache(filters.median)
>>> im = data.camera()
>>> filtered_im = median(im, np.ones((3, 3)))
__________________________
[Memory] Calling skimage.filters.rank.generic.median...
median(array([[156, ..., 152],
       ..., 
       [121, ..., 111]], dtype=uint8), array([[ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.]]))
__________________________median - 0.0s, 0.0min
>>> filtered_again = median(im, np.ones((3, 3)))
>>> # the above call did not trigger an evaluation
\end{lstlisting}

Finally, we note that the biggest performance improvements often come from
the improvement of algorithms (as opposed to computing architectures only). For
example, non-local means denoising \citep{Buades2005} is a costly operation,
since it requires several nested loops, on all pixels and on neighboring
patches to be compared with the pixel-centered patch. Thanks to the
implementation of a more recent algorithm \citep{Darbon2008} that modifies the
internal organization of loops, it was possible to gain a 5- to 10-fold speedup.
The large size of the \texttt{scikit-image} community ensures that possible
algorithmic improvements are discussed regularly.

\section*{Documentation and getting help}

The quality of the documentation is an important component to the
success of a software package.
\texttt{scikit-image} users have access to different kinds of
documentation. All functions are
documented using the NumPy documentation standard \citep{Pawlik2015},
which is universal across all major
Scientific Python packages. The standard includes a description of all
input and output variables and their data type, together with
explanations on what the function does and how to use it. Function
documentation is accessible online or within the development
environment itself (IPython, Spyder, Jupyter Notebook...).

\begin{figure*}
    \centerline{\includegraphics[width=0.99\textwidth]{figure_gallery}}
\caption{\csentence{Gallery of examples of \texttt{scikit-image}.}
 The gallery of examples consists of an array of thumbnails (left), which link to example webpages, each centerered on a specific image processing task. Each webpage includes Python code generating a figure, the figure itself, and a short tutorial explaining the image processing operations and the code. \label{fig:gallery}}
\end{figure*}

In addition, a popular documentation tool is the graphical gallery of
examples (\nolinkurl{http://scikit-image.org/docs/dev/auto_examples/}),
an example of which appears in Fig.~\ref{fig:gallery}.
The principle of the gallery is to accelerate the learning curve of image
processing, by showcasing graphical examples of common image processing
operations. Such examples are organized as an array of thumbnails with a
short title (see Fig.~\ref{fig:gallery} left). These thumbnails link to
the webpage of the corresponding example, which features a mini-tutorial
on the image processing method, the code needed to run the example and
the figure generated by the example. Since the graphical gallery is an
efficient way to inform users about the features of
\texttt{scikit-image}, every new feature integrated in the package must
include an example for the gallery.
Longer tutorials and a more narrative documentation is available as well
in the online User Guide, which explains
"big picture" aspects of \texttt{scikit-image}, such as its
use of \texttt{NumPy} arrays as images, or how the package interacts with
other parts of the scientific Python ecosystem.

Finally, tutorials on \texttt{scikit-image} are available in various
places, either as YouTube videos, or in the SciPy Lecture
Notes \citep{scipylecturenotes}, a comprehensive online book of Scientific
Python tutorials.  

\section*{Development and use of scikit-image}

\paragraph{Who uses scikit-image.}

Estimating the number of active users of an open-source package is a
difficult task. Statistics of downloads, for example, largely
overestimate the number of active users, all the more if the package is
bundled with others in a software distribution, such as Anaconda or
Canopy. A view closer to reality can be obtained by analyzing the
statistics of visits of the online help, available on the project
website.  As of the first half of 2016, 20000 unique visitors visit the
website of scikit-image every month \url{http://scikit-image.org/}. These
users come from 80 countries, located almost equally in Europe, America
and Asia (with Oceania and Africa representing a much smaller fraction of
visitors).

\paragraph{Development process.}

\texttt{scikit-image} is developed by a diverse team of volunteers.
More than 170 individuals have contributed to the package. The large
number of developers and users is a key element of the sustainability of
\texttt{scikit-image}. The
development process takes place on GitHub
\url{https://github.com/scikit-image/scikit-image}, where users and
developers propose and discuss new contributions, or report bugs or ideas
for improvements.
A release cycle of one or two releases every year
ensures that new features are proposed to users on a regular basis.

\section*{Conclusion}

\texttt{scikit-image} offers a wide variety of image processing
algorithms, using a simple interface natively compatible with 2D and 3D
images. It is well integrated into the Scientific Python ecosystem, so
that it interfaces well with visualization libraries or other data
processing packages. \texttt{scikit-image} has seen a tremendous growth
since its creation in 2010, both in terms of users and proposed features.
In addition to the growing number of scientific teams that use
\texttt{scikit-image} for processing X-ray-modalities images,
domain-specific tools are now using \texttt{scikit-image} as a dependency
to build upon. Examples include \texttt{tomopy} \citep{Gursoy2014} for
tomographic reconstruction, or \texttt{DIOPTAS} \citep{Prescher2015} for
the reduction and exploration of X-ray diffraction data. It is likely
that more application-specific software will benefit from depending on
\texttt{scikit-image} in the future, since \texttt{scikit-image} strives
to be domain-agnostic and to keep a stable interface. On the end-user
side, future work includes a better integration of parallel processing
capabilities, completion of full 3-D compatibility, an enriched narrative
documentation, and the extension of the number of algorithms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

\section*{Competing interests}
The authors declare that the research was conducted
in the absence of any commercial or financial relationships that could be
construed as a potential conflict of interest.

\section*{Acknowledgements}
  
The authors gratefully acknowledge the work of the contributors of
  \texttt{scikit-image}. E. Gouillart acknowledges the support of ANR
  project EDDAM ANR-11-BS09-027.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{refs}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Tables                        %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Use of \listoftables is discouraged.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{backmatter}
\end{document}
